<!DOCTYPE html>
<html lang="en">
<meta charset="UTF-8">
<title>Page Title</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="stylesheet" href="">
<style>
</style>
<script type="module">
    import {
        Florence2ForConditionalGeneration,
        AutoProcessor,
        AutoTokenizer,
        RawImage,
    } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@3.0.0-alpha.0';

    // Load model, processor, and tokenizer
    const model_id = 'onnx-community/Florence-2-base-ft';
    const model = await Florence2ForConditionalGeneration.from_pretrained(model_id, {
        dtype: 'fp32',
    });
    const processor = await AutoProcessor.from_pretrained(model_id);
    const tokenizer = await AutoTokenizer.from_pretrained(model_id);

    // Load image
    const url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true";
    const image = await RawImage.fromURL(url);

    // Process inputs
    const prompts = "Describe with a paragraph what is shown in the image.";
    const text_inputs = tokenizer(prompts);
    const vision_inputs = await processor(image);

    // Generate text
    const generated_ids = await model.generate({
        ...text_inputs,
        ...vision_inputs,
        max_new_tokens: 100,
    });

    // Decode generated text
    const generated_text = tokenizer.batch_decode(generated_ids, { skip_special_tokens: true });
    console.log(generated_text);
</script>

<body>

</body>

</html>